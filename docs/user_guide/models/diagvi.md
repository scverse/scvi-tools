# DiagVI

**DiagVI** (Diagonal Multi-Modal Integration Variational Inference; Python class {class}`~scvi.external.DIAGVI`) is a deep generative model for integrating unpaired multi-modal single-cell data using prior biological knowledge encoded as a guidance graph.

DiagVI is inspired by the GLUE [^ref1] architecture, which uses modality-specific variational autoencoders (VAEs) to project heterogeneous data types into a shared latent space. In contrast to GLUE’s adversarial alignment strategy, DiagVI aligns modalities using Unbalanced Optimal Transport (UOT) via the Sinkhorn divergence, explicitly accounting for differences in cell-type composition across modalities. This design makes DiagVI particularly well suited for settings with modality-specific or rare cell populations, such as the integration of spatial proteomics and scRNA-seq data.

The advantages of DiagVI are:

-   Flexible two-modality integration of various data types (e.g., scRNA-seq, spatial transcriptomics, spatial proteomics).
-   Modality specific generative likelihoods tailored to data properties.
-   Full feature utilization: all features (not only overlapping ones) contribute to model training via the guidance graph and modality-specific VAEs.
- Biologically informed alignment using prior feature correspondences via the guidance graph.
- Robust integration of modality-specific or rare cell populations via UOT.
-   Optional Gaussian mixture prior and semi-supervised learning with cell-type labels.

The limitations of DiagVI include:

-   Currently supports integration of two modalities only.
-   Requires prior information on cross-modal feature correspondences (explicitly or implicitly).
- Effectively requires a GPU for fast inference.
- Requires careful tuning of loss weights (for more information, see [Hyperparameter Selection](#hyperparameter-selection)). 

```{topic} Tutorials:
 Tutorial placeholder
```

## Preliminaries

DiagVI takes as input expression matrices $X_1 \in \mathbb{R}^{N_1 \times \mathcal{V}_1}$ and $X_2 \in \mathbb{R}^{N_2 \times \mathcal{V}_2}$ from two unpaired modalities with independent feature sets $\mathcal{V}_1, \mathcal{V}_2$ and observations $N_1, N_2$.

For count data such as scRNA-seq data DiagVI expects as input:
- A raw count expression matrix $X \in \mathbb{R}^{N \times \mathcal{V}}$, where each row is a single cell among $N$ total cells and each column is a feature (e.g., a gene) among $\mathcal{V}$ total features.
- Optionally, an experimental covariate such as batch annotation or confounding variables such as donor sex.
- Optionally, cell label annotations that weakly inform the prior of the latent space and guide a classifier in semi-supervised training.

For continuous data such as antibody-based single-cell proteomics data DiagVI expects as input:
- A transformed (and optionally scaled) protein expression matrix $X \in \mathbb{R}^{N \times \mathcal{V}}$, where each row is a single cell among $N$ total cells and each column is a feature (e.g., a marker protein) among $\mathcal{V}$ total features.
- Preprocessing expected: the input matrix is expected to be processed using for instance arcsinh or log1p transformations which are optionally followed by feature-wise scaling (e.g., z-score, min-max or rank-scaled). We recommend arcsinh transformation followed by feature-wise min-max scaling.
- Optionally, an experimental covariate such as batch annotation or confounding variables such as donor sex.
- Optionally, cell label annotations that weakly inform the prior of the latent space and guide a classifier in semi-supervised training.

Currently supported modalities include:

- scRNA-seq
- Spatial transcriptomics
- Spatial proteomics (e.g., CITE-seq, any other antibody-based single cell measurement of protein expression)
- Other count or continuous measurements

## Model components
<span style="color:red"> TODO: references </span>

<span style="color:blue"> Question: When do we use references, when links? </span>

DiagVI consists of several components which together define the overall training objective (see [Training Objective](#training-objective)).

### Modality-specific variational autoencoders
DiagVI integrates two unpaired modalities by projecting their expression matrices $X_1 \in \mathbb{R}^{N_1 \times \mathcal{V}_1}$ and $X_2 \in \mathbb{R}^{N_2 \times \mathcal{V}_2}$ into a shared latent space in which each cell is represented by a cell latent variable $\mathbf{z}$. The main assumption thereby is that the observed data from both modalities originates from a common, shared cell state based on which integration can be performed. The modality specific differences between the datasets are assumed to result from the different ways of measuring this common cell state. 

To find this shared state, the observed data from each modality is modeled using an independently parametrized VAE. The dimensionality of the embedding that is generated by this process is identical for both modalities. In this way, the observed data from both modalities is projected into a common low-dimensional space.

### Guidance graph
Projecting cells into a common low-dimensional space alone does not result in a semantically consistent embeddings in which identical cell types are assigned to the same region across both modalities. The reason for this is that the modality-specific VAEs are trained and parametrized independently. To ensure biological consistency in the latent space, a guidance graph establishes a kogical associations between the two modalities.

Feature correspondences are encoded in the guidance graph $\mathcal{G} = (\mathcal{V}, \mathcal{E})$, where $\mathcal{V} = \mathcal{V}_1 \cup \mathcal{V}_2$.
Each edge $\mathcal{E} = \{(i,j)\mid i,j \in \mathcal{V}\}$ is associated with
- a weight $w_{ij} \in (0, 1]$ reflecting the confidence of the link
- a sign $s_{ij} \in [-1, 1]$ specifying whether the interaction is associative ($s_{ij} = 1$) or repressive ($s_{ij} = -1$)

The graph loss encourages the inner product between embeddings $v_i$ and $v_j$ of linked features to be large and positive for $s_{ij} > 0$ and large and negative for $s_{ij} < 0$, with strength modulated by edge weights.

### Unbalanced optimal transport
To ensure robust alignment of cells from different modalities within a shared latent space, DiagVI leverages unbalanced optimal transport (UOT). Specifically, it minimizes the de-biased Sinkhorn divergence between latent distributions using the GeomLoss library [^ref2].
Two key parameters determine the behavior of the Sinkhorn divergence:
- `blur` - the entropic regularization strength, which controls the smoothness of the transport plan,
- `reach` - the marginal relaxation parameter, which penalizes deviations from strict mass conservation.

Although the user has the flexibility to manually specify these parameters, DiagVI uses by default the heuristic strategy introduced in [ott-jax](https://ott-jax.readthedocs.io/).
Here, `blur` is dynamically calculated at each optmization step from the cost matrix and `reach` is subsequently derived as a function of `blur`.

### Classifier
When DiagVI is trained in a semi-supervised setting, a simple cell type classifier predicting label $y$ from cell latent vector $z$ is integrated into the model and trained jointly wth the generative model.

## Descriptive model
<span style="color:red"> TODO: plate model </span>

DiagVI assumes that observations from each modality are generated from a shared 
$m$-dimensional latent space. 
For cell $n$ and feature $i$, the observed data $\mathbf{x}_{ni}$ is modelled as a function of the cell latent variable $\mathbf{z}_n \in \mathbb{R}^{m}$ and the feature latent variable  $\mathbf{v}_i \in \mathbb{R}^{m}$.

The prior on the feature (graph) latent is set to a standard normal distribution.
$$
    p(\boldsymbol{V}) \sim \prod_{i\in \mathcal{V}} N(\mathbf{v}_i;0,\boldsymbol{I_m})

$$

The prior on the cell latent variable can be either a standard Gaussian (default) or a Gaussian mixture with $L$ components.
$$
\mathbf{z}_{n} \sim
\begin{cases}
\mathcal{N}(0, 1), \\
\sum_{l=1}^L \pi_{l} \, \mathcal{N}(\mu_{l}, \sigma_{l}^2)
\end{cases}
$$
If cell-type labels are provided, a Gaussian mixture prior is used with one component per cell type. A modality-specific [classifier](#classifier) predicting labels from 
$\mathbf{z}$ is trained jointly.

## Generative process
The form of the generative model depends on whether the observed data consist of discrete counts or continuous measurements. In both cases, generation is conditioned on the cell latent variable $\mathbf{z}_n$ and feature embeddings $\mathbf{V}$.

For count-based modalities, DiagVI generates denoised and normalized expression proportions $\rho_n $ as follows:
$$
\boldsymbol{\rho}_n = \mathrm{softmax}\left( \boldsymbol{\alpha}_n \odot \left(  \mathbf{z}_n\mathbf{V}^\top \right) + \boldsymbol{\beta}_n \right)
$$
Observed counts $x_n$ are then reconstructed using the original library size $l_n$.

For continuous modalities, DiagVI generates denoised and normalized values without enforcing simplex constraints:
$$
\boldsymbol{\rho}_n = \boldsymbol{\alpha}_n \odot \left(  \mathbf{z}_n\mathbf{V}^\top \right) + \boldsymbol{\beta}_n
$$
In this case, no library size normalization is applied during reconstruction.

In both settings, $\boldsymbol{\alpha}_n \in \mathbb{R}_+^{\mid \mathcal{V} \mid}$ and $\boldsymbol{\beta}_n \in \mathbb{R}_+^{\mid \mathcal{V} \mid}$ are feature specific scaling and bias parameters, respectively. When a batch covariate is provided, DiagVI learns batch-specific versions of these parameters to account for batch effects within each modality.

## Likelihood models

Depending on the modality, different likelihood functions can be used to reconstruct the input data and the respective parameters are learned, e.g., feature-specific dispersion parameter $\boldsymbol{\theta} \in \mathbb{R}_+^{\mid \mathcal{V} \mid}$

$$
 x_{ni} \sim \text{NegativeBinomial} \left(l_n\rho_{ni}, \theta_i \right)
$$

---
DiagVI supports the following likelihood functions:

<span style="color:red">TODO: more description (maybe add a data preprocessing section?) </span>
```{eval-rst}
.. list-table::
   :widths: 20 40 40
   :header-rows: 1

   * - Likelihood
     - Distribution
     - modality type 
   * - ``nb``
     - Negative Binomial
     - scRNA-seq
   * - ``zinb``
     - Zero-Inflated Negative Binomial
     - scRNA-seq
   * - ``nbmixture``
     - Negative Binomial Mixture
     - Protein data (background/foreground)
   * - ``normal``
     - Normal
     - Protein data
   * - ``lognormal``
     - Log-Normal
     - Positive continuous data
   * - ``log1pnormal``
     - Log1p-Normal
     - Non-negative continuous data
   * - ``ziln``
     - Zero-Inflated Log-Normal
     - Sparse positive continuous data
   * - ``zig``
     - Zero-Inflated Gamma
     - Sparse positive continuous data
```

### Latent variables

<span style="color:blue"> Question: I removed library size because we never model it and always use the observed one </span>

The exact set of variables instantiated during training depends on the chosen likelihood and on whether a Gaussian mixture prior is used for the cell latent space.
```{eval-rst}
.. list-table::
   :widths: 20 70 15
   :header-rows: 1

   * - Latent variable
     - Description
     - Code variable
   * - :math:`z_n \in \mathbb{R}^m`
     - Low-dimensional latent representation of cell :math:`n`, capturing its underlying biological state
     - ``z``
   * - :math:`v_i \in \mathbb{R}^{d}`
     - Low-dimensional embedding of feature :math:`i`, learned from the guidance graph
     - ``v``
   * - :math:`\rho_n \in \Delta^{G-1)}` or :math:`\mathbb{R}^G_+`
     - Denoised, normalized expression for cell :math:`n`; constrained to the probability simplex for count data
     - ``px_scale``
   * - :math:`\theta_g \in (0, \infty)`
     - Feature-specific inverse dispersion parameters used in count-based likelihoods
     - ``px_r``
```

## Inference

DiagVI uses variational inference (see {doc}`/user_guide/background/variational_inference`) to learn model parameters and approximate posterior distributions.

## Training objective

DiagVI is trained by minimizing a weighted sum of loss terms corresponding to the [Model Components](#model-components) introduced above:
- Modality-specific VAEs: The data reconstruction loss (`lam_data`) measures how well each modality-specific decoder reconstructs the observed data, while the KL divergence (`lam_kl`) regularizes the cell latent variables by encouraging adherence to the prior.
- Guidance graph: The Gaph reconstruction loss (`lam_graph`) enforces biological consistency between feature embeddings using the guidance graph.
- UOT: The UOT alignment loss (`lam_sinkhorn`) aligns cell distributions across modalities using unbalanced optimal transport.
- Classifier: The classification loss (`lam_class`, optional) enables supervised or semi-supervised training via cell-type labels.

The `lam_*` parameters control the relative importance of within-modality reconstruction (`lam_data`, `lam_kl`), cross-modality alignment (`lam_graph`, `lam_sinkhorn`), and optional supervision (`lam_class`). DoagVI uses sensible defaults for all of these values, but they may require further tuning depending on the type of data integrated (see [Hyperparameter Selection](#hyperparameter-selection)). ).

## Practical guidance
### Hyperparameter Selection
<span style="color:red"> TODO: Provide some recommendations for parameter selection. </span>


## Tasks

Here we provide an overview of the main tasks that DiagVI can perform. See {class}`~scvi.external.DIAGVI` for the full API reference.

### Dimensionality reduction
```python
>>> latents = model.get_latent_representation()
>>> adata_rna.obsm["X_diagvi"] = latents["rna"]
>>> adata_protein.obsm["X_diagvi"] = latents["protein"]
```
Aligned representations can be used jointly for downstream analysis:

```python
>>> import scanpy as sc
>>> # Use RNA latent for clustering
>>> sc.pp.neighbors(adata_rna, use_rep="X_diagvi")
>>> sc.tl.umap(adata_rna)
>>> sc.tl.leiden(adata_rna)
```

### Cross-modal feature imputation

DiagVI can impute features from one modality to another using {func}`~scvi.external.DIAGVI.get_imputed_values`.

```python
>>> # Impute protein expression from RNA data
>>> imputed_protein = model.get_imputed_values(
...     source_name="rna",
...     source_adata=adata_rna,
... )
>>> adata_rna.obsm["imputed_protein"] = imputed_protein
```

You can also specify target batch and library size for counterfactual predictions:

```python
>>> # Impute with specific target batch
>>> imputed = model.get_imputed_values(
...     source_name="rna",
...     target_batch="batch_1",
...     target_libsize=10000,
... )
```

## References

[^ref1]:
    Cao, Zhi-Jie; Gao, Ge (2022),
    _Multi-omics single-cell data integration and regulatory inference with graph-linked embedding_,
    [Nature Biotechnology](https://www.nature.com/articles/s41587-022-01284-4).

[^ref2]:
    Feydy, Jean; Séjourné, Thibault; Vialard, François‑Xavier; Amari, Shun‑ichi; Trouvé, Alain; Peyré, Gabriel (2019)
    _Interpolating between Optimal Transport and MMD using Sinkhorn Divergences_
    [The 22nd International Conference on Artificial Intelligence and Statistics](https://arxiv.org/abs/1810.08278).

