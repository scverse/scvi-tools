# DiagVI

**DiagVI** (Diagonal Multi-Modal Integration Variational Inference; Python class {class}`~scvi.external.DIAGVI`) is a deep generative model for integrating unpaired multi-modal single-cell data using prior biological knowledge encoded as a guidance graph.

DiagVI is inspired by the GLUE [^ref1] architecture, which uses modality-specific variational autoencoders (VAEs) to project heterogeneous data types into a shared latent space. In contrast to GLUEâ€™s adversarial alignment strategy, DiagVI aligns modalities using Unbalanced Optimal Transport (UOT) via the Sinkhorn divergence, explicitly accounting for differences in cell-type composition across modalities. This design makes DiagVI particularly well suited for settings with modality-specific or rare cell populations, such as the integration of spatial proteomics and scRNA-seq.

The advantages of DiagVI are:

-   Flexible two-modality integration of various data types (e.g., scRNA-seq, spatial transcriptomics, spatial proteomics).
-   Modality specific generative likelihoods tailored to data properties.
-   Full feature utilization: all features (not only overlapping ones) contribute to model training via the guidance graph and modality-specific VAEs.
- Biologically informed alignment using prior feature correspondences via the guidance graph.
- Robust integration of modality-specific or rare cell populations via UOT.
-   Optional Gaussian mixture prior and semi-supervised learning with cell-type labels.

The limitations of DiagVI include:

-   Currently supports integration of two modalities only.
-   Requires prior information on cross-modal feature correspondences (explicitly or implicitly).
- Effectively requires a GPU for fast inference.
- Requires careful tuning of hyperparameters. 

```{topic} Tutorials:
 Tutorial placeholder
```

## Preliminaries

DiagVI takes as input expression matrices $X_1 \in \mathbb{R}^{N_1 \times \mathcal{V}_1}$ and $X_2 \in \mathbb{R}^{N_2 \times \mathcal{V}_2}$ from two unpaired modalities with independent feature sets $\mathcal{V}_1, \mathcal{V}_2$ and observations $N_1, N_2$.

For count data such as scRNA-seq data DiagVI expects as input:
- A raw count expression matrix $X \in \mathbb{R}^{N \times \mathcal{V}}$, where each row is a single cell among $N$ total cells and each column is a feature (e.g., a gene) among $\mathcal{V}$ total features.
- Optionally, experimental covariates such as batch annotations or confounding variables such as donor sex.
- Optionally, cell label annotations that weakly inform the prior of the latent space and guide a classifier in semi-supervised training.

For continuous data such as antibody-based single-cell proteomics data DiagVI expects as input:
- A transformed (and optionally scaled) protein expression matrix $X \in \mathbb{R}^{N \times \mathcal{V}}$, where each row is a single cell among $N$ total cells and each column is a feature (e.g., a marker protein) among $\mathcal{V}$ total features.
- Preprocessing expected: the input matrix is expected to be processed using for instance arcsinh, log1p, biexponential or logicle transformations which are optionally followed by feature-wise scaling (e.g., z-score, min-max or rank-scaled).
- Optionally, experimental covariates such as batch annotations or confounding variables such as donor sex.
- Optionally, cell label annotations that weakly inform the prior of the latent space and guide a classifier in semi-supervised training.

Currently supported modalities include:

- scRNA-seq
- Spatial transcriptomics
- Spatial proteomics (e.g., CITE-seq, any other antibody-based single cell measurement of protein expression)
- Other count or continuous measurements

## Model components

### Modality-specific variational autoencoders
DiagVI integrates two unpaired modalities  by projecting heterogeneous data types into a shared latent space. The main assumption thereby is that the observed data from both modalities originates from a common, shared cell state based on which integration can be performed. The modality specific differences between the datasets are assumed to result from the different ways of measuring this common cell state. 

To find this shared state, the observed data from each modality is modeled using an independently parametrized VAE. The dimensionality of the embedding that is generated by this process is identical for both modalities. In this way, the observed data from both modalities is projected into a common low-dimensional space.

This process alone does not result in a semantically consistent embedding in which identical cell types are assigned to the same region across both modalities. The reason for this is that the modality-specific VAEs are trained and parametrized independently. To ensure biological consistency in the latent space, a guidance graph establishes a kogical associations between the two modalities.

### Guidance graph and graph encoder
Feature correspondences are encoded in the guidance graph $\mathcal{G} = (\mathcal{V}, \mathcal{E})$, where $\mathcal{V} = \mathcal{V}_1 \cup \mathcal{V}_2$.
Each edge $\mathcal{E} = \{(i,j)\mid i,j \in \mathcal{V}\}$ is associated with
- a weight $w_{ij} \in (0, 1]$ reflecting the confidence of the link
- a sign $s_{ij} \in [-1, 1]$ specifying whether the interaction is associative ($s_{ij} = 1$) or repressive ($s_{ij} = -1$)

The guidance graph regularizes feature embeddings to ensure biologically meaningful alignment between modalities. There are three ways to specify it:

- Automatic construction (default): \
If no graph is provided, DiagVI constructs a graph from overlapping feature names across modalities (e.g., shared gene symbols).

- Custom mapping via DataFrame: \
Useful when feature naming conventions differ (e.g., genes vs. proteins in CITE-seq). The DataFrame specifies feature pairs and optional weights/signs.

- Explicit graph specification: \
For full control, pass a `torch_geometric.data.Data` object directly.

The graph decoder encourages embeddings $v_i$ and $v_j$ of linked features to be close in latent space, with strength modulated by edge weights and signs. Unrelated features are pushed apart.

### Unbalanced optimal transport

### Classifier

## Descriptive model
<span style="color:red"> TODO: plate model </span>

DiagVI assumes that observations from each modality are generated from a shared 
$m$-dimensional latent space. 
For cell $n$ and feature $i$, the observed data $\mathbf{x}_{ni}$ is modelled as a function of the cell latent variable $\mathbf{z}_n \in \mathbb{R}^{m}$ and the feature latent variable  $\mathbf{v}_i \in \mathbb{R}^{m}$.

The prior on the feature (graph) latent is set to a standard normal distribution.
$$
    p(\boldsymbol{V}) \sim \prod_{i\in \mathcal{V}} N(\mathbf{v}_i;0,\boldsymbol{I_m})

$$

The prior on the cell latent variable can be either a standard Gaussian (default) or a Gaussian mixture with $L$ components.
$$
\mathbf{z}_{n} \sim
\begin{cases}
\mathcal{N}(0, 1), \\
\sum_{l=1}^L \pi_{l} \, \mathcal{N}(\mu_{l}, \sigma_{l}^2)
\end{cases}
$$
If cell-type labels are provided, a Gaussian mixture prior is used with one component per cell type. A modality-specific classifier predicting labels from 
$\mathbf{z}$ is trained jointly.

## Generative process

Given cell latent $\mathbf{z}_n$ and feature embeddings $\mathbf{V}$, DiagVI generates the denoised, normalized count data
$$
\boldsymbol{\rho}_n = \mathrm{softmax}\left( \boldsymbol{\alpha}_n \odot \left(  \mathbf{z}_n\mathbf{V}^\top \right) + \boldsymbol{\beta}_n \right)
$$
where $\boldsymbol{\alpha}_n \in \mathbb{R}_+^{\mid \mathcal{V} \mid}$ and $\boldsymbol{\beta}_n \in \mathbb{R}_+^{\mid \mathcal{V} \mid}$ are feature specific scaling and bias parameters, respectively. When a batch covariate is provided, batch-specific versions of these parameters are learned. Observed library sizes $l_n$ are then used to reconstruct raw counts.

In the case of continuous measurements, again given cell latent $\mathbf{z}_n$ and feature embeddings $\mathbf{V}$, DiagVI generates denoised data 
$$
\boldsymbol{\rho}_n = \boldsymbol{\alpha}_n \odot \left(  \mathbf{z}_n\mathbf{V}^\top \right) + \boldsymbol{\beta}_n
$$
where $\boldsymbol{\alpha}_n \in \mathbb{R}_+^{\mid \mathcal{V} \mid}$ and $\boldsymbol{\beta}_n \in \mathbb{R}_+^{\mid \mathcal{V} \mid}$ are feature specific scaling and bias parameters, respectively. When a batch covariate is provided, batch-specific versions of these parameters are learned. No library size normalization is performed.

## Likelihood models

Depending on the modality, different likelihood functions can be used to reconstruct the input data and the respective parameters are learned, e.g., feature-specific dispersion parameter $\boldsymbol{\theta} \in \mathbb{R}_+^{\mid \mathcal{V} \mid}$

$$
 x_{ni} \sim \text{NegativeBinomial} \left(l_n\rho_{ni}, \theta_i \right)
$$

---
DiagVI supports the following likelihood functions:

<span style="color:red">TODO: more description (maybe add a data preprocessing section?) </span>
```{eval-rst}
.. list-table::
   :widths: 20 40 40
   :header-rows: 1

   * - Likelihood
     - Distribution
     - modality type 
   * - ``nb``
     - Negative Binomial
     - scRNA-seq
   * - ``zinb``
     - Zero-Inflated Negative Binomial
     - scRNA-seq
   * - ``nbmixture``
     - Negative Binomial Mixture
     - Protein data (background/foreground)
   * - ``normal``
     - Normal
     - Protein data
   * - ``lognormal``
     - Log-Normal
     - Positive continuous data
   * - ``log1pnormal``
     - Log1p-Normal
     - Non-negative continuous data
   * - ``ziln``
     - Zero-Inflated Log-Normal
     - Sparse positive continuous data
   * - ``zig``
     - Zero-Inflated Gamma
     - Sparse positive continuous data
```

### Latent variables
<span style="color:red">needs some overthinking</span>
```{eval-rst}
.. list-table::
   :widths: 20 70 15
   :header-rows: 1

   * - Latent variable
     - Description
     - Code variable
   * - :math:`z_n \in \mathbb{R}^m`
     - Low-dimensional cell representation capturing biological state
     - ``z``
   * - :math:`v_i \in \mathbb{R}^{d}`
     - Low-dimensional feature embedding learned via the graph encoder
     - ``v``
   * - :math:`\rho_n \in \Delta^{G-1)}` or :math:`\mathbb{R}^G_+`
     - Normalized/denoised expression (sums to 1 for count data)
     - ``px_scale``
   * - :math:`\ell_n \in (0, \infty)`
     - Observed library size (total counts per cell)
     - ``library``
   * - :math:`\theta_g \in (0, \infty)`
     - Inverse dispersion parameter (per gene/batch)
     - ``px_r``
```
Depending on the likelihood and whether a GMM prior is used, these latent variables can vary.

## Inference

DiagVI uses variational inference (see {doc}`/user_guide/background/variational_inference`) to learn model parameters and approximate posterior distributions.

### Unbalanced Optimal Transport alignment
To align modality-specific latent spaces, DiagVI minimizes the de-biased Sinkhorn divergence between latent distributions using the GeomLoss library.

Key hyperparameters:
- `blur`: entropic regularization controlling transport smoothness,
- `reach`: marginal relaxation penalizing deviations from mass conservation.

This formulation naturally handles unequal cell numbers and modality-specific populations.

### Training objective

The total loss is a weighted sum of:

- Graph reconstruction loss (`lam_graph`),
- Data reconstruction loss (`lam_data`),
- KL divergence (`lam_kl`),
- UOT alignment loss (`lam_sinkhorn`),
- Optional classification loss (`lam_class`).

## Practical guidance
### Hyperparameter Selection
<span style="color:red"> TODO: Provide some recommendations for parameter selection. </span>


## Tasks

Here we provide an overview of the main tasks that DiagVI can perform. See {class}`~scvi.external.DIAGVI` for the full API reference.

### Dimensionality reduction
```python
>>> latents = model.get_latent_representation()
>>> adata_rna.obsm["X_diagvi"] = latents["rna"]
>>> adata_protein.obsm["X_diagvi"] = latents["protein"]
```
Aligned representations can be used jointly for downstream analysis:

```python
>>> import scanpy as sc
>>> # Use RNA latent for clustering
>>> sc.pp.neighbors(adata_rna, use_rep="X_diagvi")
>>> sc.tl.umap(adata_rna)
>>> sc.tl.leiden(adata_rna)
```

### Cross-modal feature imputation

DiagVI can impute features from one modality to another using {func}`~scvi.external.DIAGVI.get_imputed_values`.

```python
>>> # Impute protein expression from RNA data
>>> imputed_protein = model.get_imputed_values(
...     source_name="rna",
...     source_adata=adata_rna,
... )
>>> adata_rna.obsm["imputed_protein"] = imputed_protein
```

You can also specify target batch and library size for counterfactual predictions:

```python
>>> # Impute with specific target batch
>>> imputed = model.get_imputed_values(
...     source_name="rna",
...     target_batch="batch_1",
...     target_libsize=10000,
... )
```

## References

[^ref1]:
    Zhi-Jie Cao, Ge Gao (2022),
    _Multi-omics single-cell data integration and regulatory inference with graph-linked embedding_,
    [Nature Biotechnology](https://www.nature.com/articles/s41587-022-01284-4).
